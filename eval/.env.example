# LLM/VLM Provider Configuration
# Copy this file to .env and fill in your API keys and endpoints

# ===== OpenAI Configuration =====
OPENAI_API_KEY=your-openai-api-key-here
# Optional: Custom OpenAI API base URL
# OPENAI_BASE_URL=https://api.openai.com/v1

# ===== Anthropic Configuration =====
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ===== Google Gemini Configuration =====
# Standard Google API
GOOGLE_API_KEY=your-google-api-key-here
GEMINI_API_KEY=your-gemini-api-key-here

# Custom Google Gemini endpoint (for custom-google provider)
CUSTOM_GOOGLE_API_KEY=your-custom-google-api-key-here
GOOGLE_BASE_URL=https://gemini.visioncoder.cn

# ===== Default Provider Settings =====
# Set default provider (openai, anthropic, google, custom-google, ollama, mock)
LLM_PROVIDER=openai
# Set default model name
LLM_MODEL=gpt-4o
# Set fallback models (comma-separated)
# LLM_FALLBACK_MODELS=qwen-vl-max,claude-3-haiku-20240307

# ===== Ollama Configuration =====
# OLLAMA_BASE_URL=http://localhost:11434
